# 📊 Wikipedia Page Web Scraping | Python, Pandas

# 📝 Description
This project scrapes the Top 100 U.S. Companies by Revenue from Wikipedia using Python libraries, cleans the extracted data using Pandas, and saves it as a CSV file for further analysis. It demonstrates the end-to-end pipeline of web data extraction, transformation, and storage.

# 🔧 Tools & Skills
Python

Jupyter Notebook

requests – For sending HTTP requests

BeautifulSoup – For parsing and navigating HTML

pandas – For data manipulation and CSV export

# 📁 Dataset
Source: Wikipedia – List of largest companies in the United States by revenue

Format: HTML table → CSV

# 🔄 Key Cleaning Steps
Accessing the Webpage

Parsing HTML

Extracting Table Headers

Extracting Table Rows

Exporting to CSV

# ✅ Key Insights
The data includes company revenue, growth %, employee count, and HQ locations — enabling deeper business insights.

Practical use-case for scraping live data, which can be extended to financial analysis, dashboards, or machine learning.

# 📥 How to Use
Clone the repo

Open the .ipynb notebook

Run the cells sequentially

Check the CSV file in your working directory

# 👤 Author
Shruti Walunj
