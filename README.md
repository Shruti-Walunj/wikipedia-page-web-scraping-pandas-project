# ğŸ“Š Wikipedia Page Web Scraping | Python, Pandas

# ğŸ“ Description
This project scrapes the Top 100 U.S. Companies by Revenue from Wikipedia using Python libraries, cleans the extracted data using Pandas, and saves it as a CSV file for further analysis. It demonstrates the end-to-end pipeline of web data extraction, transformation, and storage.

# ğŸ”§ Tools & Skills
Python

Jupyter Notebook

requests â€“ For sending HTTP requests

BeautifulSoup â€“ For parsing and navigating HTML

pandas â€“ For data manipulation and CSV export

# ğŸ“ Dataset
Source: Wikipedia â€“ List of largest companies in the United States by revenue

Format: HTML table â†’ CSV

# ğŸ”„ Key Cleaning Steps
Accessing the Webpage

Parsing HTML

Extracting Table Headers

Extracting Table Rows

Exporting to CSV

# âœ… Key Insights
The data includes company revenue, growth %, employee count, and HQ locations â€” enabling deeper business insights.

Practical use-case for scraping live data, which can be extended to financial analysis, dashboards, or machine learning.

# ğŸ“¥ How to Use
Clone the repo

Open the .ipynb notebook

Run the cells sequentially

Check the CSV file in your working directory

# ğŸ‘¤ Author
Shruti Walunj
